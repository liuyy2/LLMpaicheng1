#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
LLM Client è‡ªæµ‹è„šæœ¬

åŠŸèƒ½ï¼š
1. ä»ç¯å¢ƒå˜é‡è¯»å– API Key
2. æµ‹è¯• LLM è°ƒç”¨
3. éªŒè¯ç¼“å­˜å‘½ä¸­
4. è¾“å‡ºæ—¥å¿—åˆ° ./llm_logs/test.jsonl

ç”¨æ³•ï¼š
    # è®¾ç½®ç¯å¢ƒå˜é‡
    set DASHSCOPE_API_KEY=your_api_key   # Windows
    export DASHSCOPE_API_KEY=your_api_key  # Linux/Mac
    
    # è¿è¡Œæµ‹è¯•
    python test_llm_client.py
"""

import os
import sys
import json
import shutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from llm_client import (
    LLMClient, LLMConfig, LLMCache,
    extract_json_from_text, create_llm_client
)


def test_json_extraction():
    """æµ‹è¯• JSON ä¸‰å±‚æŠ½å–"""
    print("\n" + "="*60)
    print(" æµ‹è¯• 1: JSON ä¸‰å±‚æŠ½å–")
    print("="*60)
    
    test_cases = [
        # (è¾“å…¥, æœŸæœ›æ–¹æ³•, æœŸæœ›èƒ½è§£æ)
        ('{"w_delay": 10, "w_shift": 1}', "direct", True),
        ('```json\n{"w_delay": 15}\n```', "code_fence", True),
        ('```\n{"w_delay": 20}\n```', "code_fence", True),
        ('æˆ‘æ¥åˆ†æä¸€ä¸‹...\n\n{"w_delay": 25, "w_shift": 2}\n\nä»¥ä¸Šæ˜¯å»ºè®®', "brace_search", True),
        ('{"nested": {"a": 1, "b": 2}}', "direct", True),
        ('thinking...\n\n```json\n{"result": 42}\n```\n\ndone', "code_fence", True),
        ('no valid json here', "failed", False),
        ('just some {incomplete', "failed", False),
    ]
    
    passed = 0
    for text, expected_method, should_parse in test_cases:
        result, method = extract_json_from_text(text)
        
        method_ok = (method == expected_method)
        parse_ok = (result is not None) == should_parse
        
        if method_ok and parse_ok:
            status = "âœ“ PASS"
            passed += 1
        else:
            status = "âœ— FAIL"
        
        # æˆªæ–­æ˜¾ç¤º
        display = text[:40].replace('\n', '\\n')
        if len(text) > 40:
            display += "..."
        
        print(f"  {status}: method={method:12} expected={expected_method:12} | {display}")
    
    print(f"\n  ç»“æœ: {passed}/{len(test_cases)} é€šè¿‡")
    return passed == len(test_cases)


def test_cache_key():
    """æµ‹è¯•ç¼“å­˜ key è®¡ç®—"""
    print("\n" + "="*60)
    print(" æµ‹è¯• 2: ç¼“å­˜ Key è®¡ç®—")
    print("="*60)
    
    # ç›¸åŒè¾“å…¥åº”è¯¥ç”Ÿæˆç›¸åŒ key
    key1 = LLMCache.compute_cache_key(
        model="Qwen/Qwen3-32B",
        messages=[{"role": "user", "content": "æµ‹è¯•"}],
        temperature=0.0,
        top_p=1.0,
        max_tokens=256
    )
    
    key2 = LLMCache.compute_cache_key(
        model="Qwen/Qwen3-32B",
        messages=[{"role": "user", "content": "æµ‹è¯•"}],
        temperature=0.0,
        top_p=1.0,
        max_tokens=256
    )
    
    # ä¸åŒè¾“å…¥åº”è¯¥ç”Ÿæˆä¸åŒ key
    key3 = LLMCache.compute_cache_key(
        model="Qwen/Qwen3-32B",
        messages=[{"role": "user", "content": "æµ‹è¯•2"}],
        temperature=0.0,
        top_p=1.0,
        max_tokens=256
    )
    
    key4 = LLMCache.compute_cache_key(
        model="Qwen/Qwen3-32B",
        messages=[{"role": "user", "content": "æµ‹è¯•"}],
        temperature=0.5,  # ä¸åŒæ¸©åº¦
        top_p=1.0,
        max_tokens=256
    )
    
    tests = [
        ("ç›¸åŒè¾“å…¥ç”Ÿæˆç›¸åŒ key", key1 == key2),
        ("ä¸åŒå†…å®¹ç”Ÿæˆä¸åŒ key", key1 != key3),
        ("ä¸åŒæ¸©åº¦ç”Ÿæˆä¸åŒ key", key1 != key4),
        ("Key é•¿åº¦ä¸º 64 (SHA256)", len(key1) == 64),
    ]
    
    passed = 0
    for desc, result in tests:
        status = "âœ“ PASS" if result else "âœ— FAIL"
        print(f"  {status}: {desc}")
        if result:
            passed += 1
    
    print(f"\n  Key ç¤ºä¾‹: {key1[:32]}...")
    print(f"  ç»“æœ: {passed}/{len(tests)} é€šè¿‡")
    return passed == len(tests)


def test_cache_operations():
    """æµ‹è¯•ç¼“å­˜è¯»å†™"""
    print("\n" + "="*60)
    print(" æµ‹è¯• 3: ç¼“å­˜è¯»å†™æ“ä½œ")
    print("="*60)
    
    # ä½¿ç”¨ä¸´æ—¶ç›®å½•
    test_cache_dir = "./llm_logs/.test_cache"
    
    try:
        # æ¸…ç†æ—§ç¼“å­˜
        if os.path.exists(test_cache_dir):
            shutil.rmtree(test_cache_dir)
        
        cache = LLMCache(test_cache_dir)
        
        # æµ‹è¯•å†™å…¥
        test_key = "test_key_12345"
        test_data = {"raw_text": "test response", "tokens_total": 100}
        
        write_ok = cache.set(test_key, test_data)
        print(f"  å†™å…¥ç¼“å­˜: {'âœ“' if write_ok else 'âœ—'}")
        
        # æµ‹è¯•è¯»å–
        read_data = cache.get(test_key)
        read_ok = read_data is not None and read_data.get("raw_text") == "test response"
        print(f"  è¯»å–ç¼“å­˜: {'âœ“' if read_ok else 'âœ—'}")
        
        # æµ‹è¯•ä¸å­˜åœ¨çš„ key
        missing = cache.get("nonexistent_key")
        missing_ok = missing is None
        print(f"  ç¼ºå¤±è¿”å› None: {'âœ“' if missing_ok else 'âœ—'}")
        
        # æµ‹è¯•ç»Ÿè®¡
        stats = cache.stats()
        stats_ok = stats["num_entries"] == 1
        print(f"  ç»Ÿè®¡æ­£ç¡®: {'âœ“' if stats_ok else 'âœ—'} (entries={stats['num_entries']})")
        
        # æµ‹è¯•æ¸…ç©º
        cleared = cache.clear()
        clear_ok = cleared == 1 and cache.get(test_key) is None
        print(f"  æ¸…ç©ºç¼“å­˜: {'âœ“' if clear_ok else 'âœ—'} (cleared={cleared})")
        
        passed = sum([write_ok, read_ok, missing_ok, stats_ok, clear_ok])
        print(f"\n  ç»“æœ: {passed}/5 é€šè¿‡")
        
        return passed == 5
        
    finally:
        # æ¸…ç†
        if os.path.exists(test_cache_dir):
            shutil.rmtree(test_cache_dir)


def test_llm_api():
    """æµ‹è¯•çœŸå® LLM API è°ƒç”¨"""
    print("\n" + "="*60)
    print(" æµ‹è¯• 4: çœŸå® LLM API è°ƒç”¨")
    print("="*60)
    
    # æ£€æŸ¥ API Key
    api_key = os.environ.get("DASHSCOPE_API_KEY", "")
    if not api_key:
        print("  âš  æœªè®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ï¼Œè·³è¿‡ API æµ‹è¯•")
        print("  è®¾ç½®æ–¹æ³•:")
        print("    Windows: set DASHSCOPE_API_KEY=your_key")
        print("    Linux:   export DASHSCOPE_API_KEY=your_key")
        return None  # è·³è¿‡ä½†ä¸ç®—å¤±è´¥
    
    print(f"  API Key: {api_key[:8]}...{api_key[-4:]}")
    
    # é…ç½®
    cache_dir = "./llm_logs/test_cache"
    log_file = "./llm_logs/test.jsonl"
    
    # æ¸…ç†æ—§æ—¥å¿—å’Œç¼“å­˜
    if os.path.exists(log_file):
        os.remove(log_file)
    if os.path.exists(cache_dir):
        shutil.rmtree(cache_dir)
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    config = LLMConfig(
        api_key=api_key,
        base_url="https://api-inference.modelscope.cn/v1",
        model="Qwen/Qwen3-32B",
        temperature=0.0,
        max_tokens=64,
        timeout_s=30.0,
        max_retries=3,
        cache_dir=cache_dir,
        log_file=log_file,
        enable_thinking=False
    )
    
    print(f"\n  é…ç½®:")
    print(f"    Model: {config.model}")
    print(f"    Base URL: {config.base_url}")
    print(f"    Cache Dir: {cache_dir}")
    print(f"    Log File: {log_file}")
    
    try:
        client = LLMClient(config)
    except Exception as e:
        print(f"\n  âœ— å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ¶ˆæ¯ï¼ˆæçŸ­ï¼‰
    test_messages = [
        {"role": "user", "content": "è¯·ç”¨ä¸€ä¸ªè¯å›ç­”ï¼š1+1=?"}
    ]
    
    # ========== ç¬¬ä¸€æ¬¡è°ƒç”¨ ==========
    print("\n  --- ç¬¬ä¸€æ¬¡è°ƒç”¨ (åº”è¯¥è°ƒç”¨ API) ---")
    
    try:
        result1 = client.call(messages=test_messages)
        
        print(f"    success: {result1.success}")
        print(f"    cache_hit: {result1.cache_hit}")
        print(f"    latency_ms: {result1.latency_ms}")
        print(f"    tokens_prompt: {result1.tokens_prompt}")
        print(f"    tokens_completion: {result1.tokens_completion}")
        print(f"    tokens_total: {result1.tokens_total}")
        print(f"    finish_reason: {result1.finish_reason}")
        print(f"    raw_text: {result1.raw_text[:100] if result1.raw_text else 'None'}...")
        
        if not result1.success:
            print(f"    error: {result1.error_type}: {result1.error_message}")
            return False
        
        call1_ok = result1.success and not result1.cache_hit
        print(f"    éªŒè¯: {'âœ“' if call1_ok else 'âœ—'} (success=True, cache_hit=False)")
        
    except Exception as e:
        print(f"    âœ— è°ƒç”¨å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # ========== ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆç›¸åŒå†…å®¹ï¼Œåº”å‘½ä¸­ç¼“å­˜ï¼‰==========
    print("\n  --- ç¬¬äºŒæ¬¡è°ƒç”¨ (åº”è¯¥å‘½ä¸­ç¼“å­˜) ---")
    
    try:
        result2 = client.call(messages=test_messages)
        
        print(f"    success: {result2.success}")
        print(f"    cache_hit: {result2.cache_hit}")
        print(f"    latency_ms: {result2.latency_ms}")
        print(f"    raw_text: {result2.raw_text[:100] if result2.raw_text else 'None'}...")
        
        call2_ok = result2.success and result2.cache_hit
        print(f"    éªŒè¯: {'âœ“' if call2_ok else 'âœ—'} (success=True, cache_hit=True)")
        
        # éªŒè¯ç¼“å­˜å†…å®¹ä¸€è‡´
        content_ok = result1.raw_text == result2.raw_text
        print(f"    å†…å®¹ä¸€è‡´: {'âœ“' if content_ok else 'âœ—'}")
        
    except Exception as e:
        print(f"    âœ— è°ƒç”¨å¼‚å¸¸: {e}")
        return False
    
    # ========== ç¬¬ä¸‰æ¬¡è°ƒç”¨ï¼ˆä¸åŒå†…å®¹ï¼Œåº”è°ƒç”¨ APIï¼‰==========
    print("\n  --- ç¬¬ä¸‰æ¬¡è°ƒç”¨ (ä¸åŒå†…å®¹ï¼Œåº”è°ƒç”¨ API) ---")
    
    try:
        result3 = client.call(
            messages=[{"role": "user", "content": "è¯·ç”¨ä¸€ä¸ªè¯å›ç­”ï¼š2+2=?"}]
        )
        
        print(f"    success: {result3.success}")
        print(f"    cache_hit: {result3.cache_hit}")
        print(f"    latency_ms: {result3.latency_ms}")
        
        call3_ok = result3.success and not result3.cache_hit
        print(f"    éªŒè¯: {'âœ“' if call3_ok else 'âœ—'} (success=True, cache_hit=False)")
        
    except Exception as e:
        print(f"    âœ— è°ƒç”¨å¼‚å¸¸: {e}")
        return False
    
    # ========== ç»Ÿè®¡ ==========
    print("\n  --- å®¢æˆ·ç«¯ç»Ÿè®¡ ---")
    stats = client.get_stats()
    print(f"    total_calls: {stats['total_calls']}")
    print(f"    cache_hits: {stats['cache_hits']}")
    print(f"    api_calls: {stats['api_calls']}")
    print(f"    cache_hit_rate: {stats['cache_hit_rate']:.2%}")
    print(f"    total_tokens: {stats['total_tokens']}")
    
    stats_ok = (
        stats['total_calls'] == 3 and
        stats['cache_hits'] == 1 and
        stats['api_calls'] == 2
    )
    print(f"    éªŒè¯: {'âœ“' if stats_ok else 'âœ—'} (calls=3, hits=1, api=2)")
    
    # ========== æ—¥å¿—éªŒè¯ ==========
    print("\n  --- æ—¥å¿—éªŒè¯ ---")
    if os.path.exists(log_file):
        with open(log_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        print(f"    æ—¥å¿—æ–‡ä»¶å­˜åœ¨: âœ“")
        print(f"    æ—¥å¿—è¡Œæ•°: {len(lines)}")
        
        log_ok = len(lines) == 3
        print(f"    éªŒè¯: {'âœ“' if log_ok else 'âœ—'} (åº”è¯¥æœ‰ 3 è¡Œ)")
        
        # æ˜¾ç¤ºæ—¥å¿—å†…å®¹
        print("\n    æ—¥å¿—å†…å®¹é¢„è§ˆ:")
        for i, line in enumerate(lines):
            log_entry = json.loads(line)
            print(f"      [{i+1}] cache_hit={log_entry['cache_hit']}, "
                  f"latency={log_entry['latency_ms']}ms, "
                  f"tokens={log_entry['tokens_total']}")
    else:
        print(f"    æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: âœ—")
        log_ok = False
    
    # ========== æ€»ç»“ ==========
    all_passed = call1_ok and call2_ok and content_ok and call3_ok and stats_ok and log_ok
    print(f"\n  ç»“æœ: {'å…¨éƒ¨é€šè¿‡ âœ“' if all_passed else 'å­˜åœ¨å¤±è´¥ âœ—'}")
    
    return all_passed


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*60)
    print(" LLM Client è‡ªæµ‹è„šæœ¬")
    print("="*60)
    print(f" å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f" Python: {sys.version.split()[0]}")
    
    results = {}
    
    # æµ‹è¯• 1: JSON æŠ½å–
    results["json_extraction"] = test_json_extraction()
    
    # æµ‹è¯• 2: ç¼“å­˜ key
    results["cache_key"] = test_cache_key()
    
    # æµ‹è¯• 3: ç¼“å­˜æ“ä½œ
    results["cache_operations"] = test_cache_operations()
    
    # æµ‹è¯• 4: API è°ƒç”¨
    api_result = test_llm_api()
    if api_result is not None:
        results["api_call"] = api_result
    
    # æ€»ç»“
    print("\n" + "="*60)
    print(" æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    for name, passed in results.items():
        status = "âœ“ PASS" if passed else "âœ— FAIL"
        print(f"  {status}: {name}")
    
    total_passed = sum(1 for v in results.values() if v)
    total_tests = len(results)
    
    print(f"\n  æ€»è®¡: {total_passed}/{total_tests} é€šè¿‡")
    
    if total_passed == total_tests:
        print("\n  ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return 0
    else:
        print("\n  âš  å­˜åœ¨æµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    sys.exit(main())
